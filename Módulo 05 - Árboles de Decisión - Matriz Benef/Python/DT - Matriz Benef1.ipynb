{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DT - Matriz Benef1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"qANbYEinvqPY"},"source":["# Importamos dataset"]},{"cell_type":"code","metadata":{"id":"bTP8q2Q5mjF4"},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Re7c4tHAnJy0"},"source":["# importamos el CHURN\n","\n","churn = pd.read_csv('/content/drive/MyDrive/4- Data Science/FIUBA - Curso Ciencia de Datos - 1er Cuatrimestre 2021/Módulo  05 - Árboles de Decisión - Matriz Benef/Churn_Modelling.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oOzb8v3FpI_w","colab":{"base_uri":"https://localhost:8080/","height":197},"executionInfo":{"status":"ok","timestamp":1620940380867,"user_tz":180,"elapsed":630,"user":{"displayName":"Federico Cardoso","photoUrl":"","userId":"07880001849925101622"}},"outputId":"756b21c1-b930-431f-e268-9d068335ca94"},"source":["churn.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>RowNumber</th>\n","      <th>CustomerId</th>\n","      <th>Surname</th>\n","      <th>CreditScore</th>\n","      <th>Geography</th>\n","      <th>Gender</th>\n","      <th>Age</th>\n","      <th>Tenure</th>\n","      <th>Balance</th>\n","      <th>NumOfProducts</th>\n","      <th>HasCrCard</th>\n","      <th>IsActiveMember</th>\n","      <th>EstimatedSalary</th>\n","      <th>Exited</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>15634602</td>\n","      <td>Hargrave</td>\n","      <td>619</td>\n","      <td>France</td>\n","      <td>Female</td>\n","      <td>42</td>\n","      <td>2</td>\n","      <td>0.00</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>101348.88</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>15647311</td>\n","      <td>Hill</td>\n","      <td>608</td>\n","      <td>Spain</td>\n","      <td>Female</td>\n","      <td>41</td>\n","      <td>1</td>\n","      <td>83807.86</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>112542.58</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>15619304</td>\n","      <td>Onio</td>\n","      <td>502</td>\n","      <td>France</td>\n","      <td>Female</td>\n","      <td>42</td>\n","      <td>8</td>\n","      <td>159660.80</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113931.57</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>15701354</td>\n","      <td>Boni</td>\n","      <td>699</td>\n","      <td>France</td>\n","      <td>Female</td>\n","      <td>39</td>\n","      <td>1</td>\n","      <td>0.00</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>93826.63</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>15737888</td>\n","      <td>Mitchell</td>\n","      <td>850</td>\n","      <td>Spain</td>\n","      <td>Female</td>\n","      <td>43</td>\n","      <td>2</td>\n","      <td>125510.82</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>79084.10</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   RowNumber  CustomerId   Surname  ...  IsActiveMember EstimatedSalary Exited\n","0          1    15634602  Hargrave  ...               1       101348.88      1\n","1          2    15647311      Hill  ...               1       112542.58      0\n","2          3    15619304      Onio  ...               0       113931.57      1\n","3          4    15701354      Boni  ...               0        93826.63      0\n","4          5    15737888  Mitchell  ...               1        79084.10      0\n","\n","[5 rows x 14 columns]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"hMBp0iHkpKa3"},"source":["churn.drop(columns = ['RowNumber', 'CustomerId', 'Surname'], inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zHQzgcMrpjSJ"},"source":["churn.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BbsJkDjR060Z","executionInfo":{"status":"ok","timestamp":1620944666598,"user_tz":180,"elapsed":597,"user":{"displayName":"Federico Cardoso","photoUrl":"","userId":"07880001849925101622"}},"outputId":"9e0a5a5d-8813-47e6-de0a-82fbaf110f6a"},"source":["import this"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The Zen of Python, by Tim Peters\n","\n","Beautiful is better than ugly.\n","Explicit is better than implicit.\n","Simple is better than complex.\n","Complex is better than complicated.\n","Flat is better than nested.\n","Sparse is better than dense.\n","Readability counts.\n","Special cases aren't special enough to break the rules.\n","Although practicality beats purity.\n","Errors should never pass silently.\n","Unless explicitly silenced.\n","In the face of ambiguity, refuse the temptation to guess.\n","There should be one-- and preferably only one --obvious way to do it.\n","Although that way may not be obvious at first unless you're Dutch.\n","Now is better than never.\n","Although never is often better than *right* now.\n","If the implementation is hard to explain, it's a bad idea.\n","If the implementation is easy to explain, it may be a good idea.\n","Namespaces are one honking great idea -- let's do more of those!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6qf-bXvAvtVm"},"source":["# Preparamos la data"]},{"cell_type":"code","metadata":{"id":"iGtxwvPrpkjA"},"source":["X = churn.drop('Exited', axis=1).values\n","y = churn['Exited'].values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TuPGrSDQrEn2"},"source":["# importamos la libreria para poder realizar el One Hot Encoding\n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.model_selection import train_test_split\n","\n","# Como podemos ver, las columnas que tienen los valores categoricos son la segunda y la tercera (Geography y Gender)\n","\n","cl = ColumnTransformer(transformers = [('OHE', OneHotEncoder(drop='first'), [1, 2])], remainder = 'passthrough')\n","                                       \n","X = cl.fit_transform(X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VDRwxwN54ikG"},"source":["ohe_columns = cl.get_feature_names()\n","ohe_columns"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FIO4XbPxjqWy"},"source":["churn_columns = [col for col in churn.columns if col not in ['Geography', 'Gender', 'Exited']]\n","churn_columns"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1j0bocvMjqWy"},"source":["final_columns = ohe_columns[:3] + churn_columns\n","final_columns"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cPWalHn2jqWz"},"source":["X = pd.DataFrame(X, columns=final_columns)\n","X"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UJZSJ5vKpIDQ"},"source":["X_train, X_test, y_train, y_test = train_test_split(X, y,\n","                                                    test_size = 0.2,\n","                                                    stratify = y,\n","                                                    random_state = 25)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fhc_Pl_vv4pk"},"source":["# Construimos el modelo"]},{"cell_type":"code","metadata":{"id":"cAxXF_K5njMM"},"source":["# importamos las librerias necesarias para el modelo\n","\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn import tree"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"84RLLTyUqcZ8"},"source":["# definimos los parametros del arbol\n","\n","dt = DecisionTreeClassifier(criterion='gini', \n","                            max_depth=3,\n","                            min_samples_leaf = 0.08)\n","\n","# entrenamos el modelo como siempre en sklearn\n","dt.fit(X_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IFzwDwKer87c","scrolled":false},"source":["# utilizamos la libreria que importamos de tree, para graficar los splits del arbol\n","\n","plt.figure(figsize=(500,180))\n","\n","tree.plot_tree(dt.fit(X_train, y_train), feature_names=X.columns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H2LxH2VKjqW4"},"source":["# vamos a conocer algunas propiedades del arbol\n","\n","print(f\"La profundidad del arbol entrenado es {dt.get_depth()}\")\n","print(f\"La cantidad de nodos terminales es {dt.get_n_leaves()}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cuzTIQnvjqW4"},"source":["dt.get_params(deep=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E9Uq1iEOjqW5"},"source":["print(tree.export_text(dt, feature_names=final_columns))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T6aGBP8pxhma"},"source":["# Prediccion"]},{"cell_type":"code","metadata":{"id":"6UvY8SDpYn3V"},"source":["# importamos las librerias para obtener metricas de los resultados\n","\n","from sklearn.metrics import confusion_matrix, accuracy_score"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5hKEJPDd15ut"},"source":["## Umbral = 0.5"]},{"cell_type":"markdown","metadata":{"id":"o88nr8QOzIBd"},"source":["### Prediccion umbral"]},{"cell_type":"code","metadata":{"id":"VQHYxMLZuMVL"},"source":["# por defecto, el metodo predict realiza la clasificacion de la probabilidad con un umbral de 0.5\n","\n","y_pred = dt.predict(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P6d4rf9vr4ZS"},"source":["# calculamos el accuracy del modelo\n","\n","accuracy_score(y_test, y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RWMzDseGys5q"},"source":["confusion_matrix(y_test, y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7rSthbkTzs8d"},"source":["# descomponemos la matriz de confusion en los cuatro posibles resultados\n","\n","tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4trEK-DAz0ST"},"source":["# Revisamos el calculo del accuracy con los datos que nos entrega la matriz\n","\n","(tn + tp) / (tn + fp + fn + tp)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ANKcBaRP7Rvf"},"source":["p_tp = tp / (tn + fp + fn + tp)\n","p_fn = fn / (tn + fp + fn + tp)\n","p_tn = tn / (tn + fp + fn + tp)\n","p_fp = fp / (tn + fp + fn + tp)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J7GJUP9HBwMf"},"source":["p_tp"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"doE4TfqaBxmd"},"source":["p_fn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qC2JU-wuByju"},"source":["p_tn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZLAJkplJBzdb"},"source":["p_fp"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oDBmw2Sa12XQ"},"source":["### Matriz de beneficio "]},{"cell_type":"code","metadata":{"id":"QQ4NvMrh11q3"},"source":["# vamos a definir los beneficios/costos asociados a cada alternativa\n","\n","b_tp = 750\n","b_tn = 100\n","c_fp = -200\n","c_fn = -950"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3cMAnRiQ5DGj"},"source":["# obtenemos la proporcion de cada clase, para esto vamos a utilizar un metodo de pandas llamado .value_counts\n","# el argumento de normalize = True nos permite obtener en vez del recuento de valores, la proporcion.\n","\n","proporcion = churn['Exited'].value_counts(normalize = True)\n","proporcion"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kKWyNM2a6bNB"},"source":["valor_esperado = p_tp * b_tp + p_fn * c_fn + p_tn * b_tn + p_fp * c_fp\n","valor_esperado"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XqEDPkbl-FCC"},"source":["## Umbral = 0.2"]},{"cell_type":"markdown","metadata":{"id":"qXch7Z6D-JRy"},"source":["### Prediccion umbral"]},{"cell_type":"code","metadata":{"id":"tDfEXegP9xEe"},"source":["# vamos a tener que especializar la probabilidad en el valor que deseamos, en este caso 0.2\n","\n","y_pred = dt.predict_proba(X_test)[:, 1] > 0.2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Mw3oGHy-_CF"},"source":["# calculamos el accuracy del modelo\n","\n","accuracy_score(y_test, y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C88YmXh_AOgN"},"source":["confusion_matrix(y_test, y_pred) / 2000"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QK0Z_LCmAUad"},"source":["# descomponemos la matriz de confusion en los cuatro posibles resultados\n","\n","tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iBWF3YcYAXV9"},"source":["p_tp = tp / (tn + fp + fn + tp)\n","p_fn = fn / (tn + fp + fn + tp)\n","p_tn = tn / (tn + fp + fn + tp)\n","p_fp = fp / (tn + fp + fn + tp)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xG96vqpT-MFy"},"source":["### Matriz de beneficio"]},{"cell_type":"code","metadata":{"id":"LL-y1Mba-OL7"},"source":["# como ya tenemos todas las demas matrices construidas, solo nos resta volver a realizar el calculo del valor esperado\n","\n","valor_esperado = p_tp * b_tp + p_fn * c_fn + p_tn * b_tn + p_fp * c_fp\n","valor_esperado"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s8ovhckYA6BL"},"source":["## Umbral = 0.1"]},{"cell_type":"markdown","metadata":{"id":"pegpydOuA8M1"},"source":["### Prediccion"]},{"cell_type":"code","metadata":{"id":"bYpL4zhiAi89"},"source":["# vamos a tener que especializar la probabilidad en el valor que deseamos, en este caso 0.1\n","\n","y_pred = dt.predict_proba(X_test)[:, 1] > 0.1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4dXIjNvOBChU"},"source":["# calculamos el accuracy del modelo\n","\n","accuracy_score(y_test, y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1KwiumMLBEX9"},"source":["confusion_matrix(y_test, y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gcgrHV29BGjt"},"source":["# descomponemos la matriz de confusion en los cuatro posibles resultados\n","\n","tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HrVSKvD9BKWd"},"source":["p_tp = tp / (tn + fp + fn + tp)\n","p_fn = fn / (tn + fp + fn + tp)\n","p_tn = tn / (tn + fp + fn + tp)\n","p_fp = fp / (tn + fp + fn + tp)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D1iAJHm5A9Zi"},"source":["### Matriz de beneficio"]},{"cell_type":"code","metadata":{"id":"4hJ_jeB_A_zs"},"source":["# como ya tenemos todas las demas matrices construidas, solo nos resta volver a realizar el calculo del valor esperado\n","\n","valor_esperado = p_tp * b_tp + p_fn * c_fn + p_tn * b_tn + p_fp * c_fp\n","valor_esperado"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BV56ifoIjqXF"},"source":["## ROC CURVE"]},{"cell_type":"code","metadata":{"id":"cTqlBrHRjqXF"},"source":["# para construir la roc curve, importaremos la libreria y luego utilizaremos la libreria para obtener \n","\n","from sklearn.metrics import roc_curve\n","\n","y_pred_prob = dt.predict_proba(X_test)[:,1]\n","fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n","plt.plot([0, 1], [0, 1], 'k--')\n","plt.plot(fpr, tpr, label='Logistic Regression')\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Logistic Regression ROC Curve')\n","plt.show();"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8j34KpF8jqXF"},"source":["thresholds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_-9d1eg8jqXG"},"source":["fpr"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ylGAilMJjqXG"},"source":["tpr"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IKP1cYeyjqXG"},"source":["### AUC"]},{"cell_type":"code","metadata":{"id":"qcq95YR6jqXG"},"source":["# una metrica importante es el area debajo del a curva roc y para calcularla utilizaremos la libreria\n","from sklearn.metrics import roc_auc_score\n","\n","y_pred_prob = dt.predict_proba(X_test)[:,1]\n","print(f'El area debajo de la curva ROC es: {roc_auc_score(y_test, y_pred_prob):.3f}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1NVhKxlKmgfo"},"source":["# Actividades propuestas"]},{"cell_type":"markdown","metadata":{"id":"b3q1Po6qmjxA"},"source":["1- Probar diferentes combinaciones de hiperparametros y encontrar la que mejor se ajusta a este problema.\n","\n","2- Determinar cuales son las principales variables que estan influyendo en la decision del arbol.\n","\n","3- Generar la prediccion tanto para el test como para el train set, buscando visualizar la relacion de los hiperparametros con el concepto de overfitting y underfitting."]}]}