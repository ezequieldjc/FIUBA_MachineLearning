{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Clustering-checkpoint.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"qANbYEinvqPY"},"source":["# Importamos dataset"]},{"cell_type":"code","metadata":{"id":"bTP8q2Q5mjF4"},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Re7c4tHAnJy0"},"source":["# importamos el dataset de Mall Customers\n","mall = pd.read_csv(\"Mall_Customers.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oOzb8v3FpI_w"},"source":["mall.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2BHOeCulKpId"},"source":["mall.info()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zHQzgcMrpjSJ"},"source":["# solo utilizaremos la columnas 4 y 5\n","# mall.drop(columns=['CustomerID', 'Genre', 'Age'], inplace=True)\n","mall.drop(columns=['CustomerID', 'Genre', 'Age'], inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6qf-bXvAvtVm"},"source":["# Clustering"]},{"cell_type":"code","metadata":{"id":"5_Je6ZCCJN4W"},"source":["# importamos las librerias necesarias para realizar el clustering\n","from sklearn.cluster import KMeans"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9xo-zPksIz6Q"},"source":["# inicializamos un diccionario para poder guardar la 'inertia' de cada grupo\n","clusters = {'n': [], 'inertia': []}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mhfg6uFhIzn-"},"source":["# utilizaremos un bucle for para probar diferentes cantidades de clusters y almacenarlas en el diccionario\n","# luego de este ejercicio utilizaremos el metodo del codo (elbow) para encontrar la cantidad optima\n","\n","for i in range(1, 11):\n","  model = KMeans(n_clusters=i, random_state=123)\n","  model.fit(mall)\n","  inertia = model.inertia_\n","\n","  clusters['n'].append(i)\n","  clusters['inertia'].append(inertia)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lMvSbTh1Izb8"},"source":["sns.set_style('whitegrid')\n","pd.DataFrame(clusters).plot(x='n', y='inertia', kind='line', marker='o')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d7ny8-gWM1f8"},"source":["# vemos que la cantidad optima de clusters es 5\n","# armamos un modelo para predecir los valores actuales del dataset mall\n","kmeans = KMeans(n_clusters=5)\n","\n","# entrenamos con los datos del dataset\n","kmeans.fit(mall)\n","\n","# generamos un arreglo donde se almacenan las clases predichas por el modelo\n","pred_class = kmeans.predict(mall)\n","\n","# adicionamos al dataframe mall el valor de cada clase en una columna nueva\n","mall['Clase'] = pred_class"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dNb_tIHBN7-W"},"source":["# visualizamos las clases en el scatterplot a traves de los diferentes colores\n","\n","sns.scatterplot(x='Annual Income (k$)', y='Spending Score (1-100)', hue='Clase', data=mall, palette=sns.color_palette(\"Paired\", 5))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"381kIbPEfgxK"},"source":["# Clustering Jerarquico\n"]},{"cell_type":"code","metadata":{"id":"qbvFwfQYfuzm"},"source":["# en este caso vamos a necesitar utilizar la libreria de SciPy\n","\n","from scipy.cluster.hierarchy import linkage, dendrogram"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"75IXxRB4f8pH"},"source":["# vamos a generar el dendograma con distancia euclidea y disimilitud ward\n","# la computacion del algoritmo se genera en la siguiente linea de codigo\n","dend = linkage(mall, method='ward', metric='euclidean')\n","\n","# utilizamos la funcion dendogram que tambien importamos de SciPy para graficarlo\n","plt.figure(figsize=(25, 15))\n","dendrogram(dend, leaf_rotation=90, leaf_font_size=6)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jxjVBxp5VULb"},"source":["# ahora podemos elegir a la altura sobre la cual deseamos cortar el cluster\n","# para esto debemos importar otra funcionalidad de SciPy llamada fcluster\n","\n","from scipy.cluster.hierarchy import fcluster\n","\n","# el proceso es sencillo, simplemente elegimos como argumentos  el modelo que hicimos\n","# previamente llamado dend, a que distancia queremos generar los clusters y con que criterio\n","# 150 parece un buen punto para el corte, y pensemos, cuantos clusters deberian aparecer como maximo\n","\n","labels = fcluster(dend, 150, criterion='distance')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GFPZHQBCWp36"},"source":["# veamos cual es el valor mas alto de un cluster, tiene sentido en funcion al grafico?\n","max(labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PNckll_SWZJk"},"source":["# solo nos falta agregar al dataframe del mall esta nueva categorizacion\n","# para ello crearemos una nueva columna la cual llamaremos clase_dend\n","\n","mall['clase_dend'] = labels"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mCZX9mMGXAb3"},"source":["# visualizamos las clases en el scatterplot a traves de los diferentes colores\n","sns.scatterplot(x='Annual Income (k$)', y='Spending Score (1-100)', hue='clase_dend', data=mall, palette=sns.color_palette(\"Paired\", 5))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kw-HKGlirF6M"},"source":[""],"execution_count":null,"outputs":[]}]}