{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"KNN_RL_CV - SIMPLE - CHURN - Alumnos.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"JyzaKIzXONBZ"},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I0e8Ng3MVwwG"},"source":["# Importamos dataset"]},{"cell_type":"code","metadata":{"id":"7utH3XRdxXtK"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T-_XVg4XQZlu"},"source":["# Revisar las 5 primeras filas del dataset\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E6RQRoUaV4jT"},"source":["# Analisis exploratorio de los datos"]},{"cell_type":"markdown","metadata":{"id":"Y-y0sztBQhAh"},"source":["## Dataset Churn"]},{"cell_type":"code","metadata":{"id":"TkCZt9_5Qbg-"},"source":["# Imprimir la informacion de los tipos de datos que tiene el dataset\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PD_X9ffE091T"},"source":["# Generar un resumen estadistico de las columnas numericas\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TYi7I6JNQRiS"},"source":["# borramos las columnas categóricas y aquellas numericas que no hacen sentido y generan ruido en el modelo.\n","\n","churn.drop(['RowNumber', _______, 'Surname', _______, 'Gender'], axis=1, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XJ0fnOY-S8xS"},"source":["# guardamos los atributos en un NumPy Array, ya que es el formato en el cual nos sklearn recibe los datos\n","\n","X = churn.loc[:, churn.columns != 'Exited'].values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lEpXhWpG6iBj"},"source":["# guardar el target en la variable y\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gfJgi_cHjqYG"},"source":["# Train/Test Spit"]},{"cell_type":"markdown","metadata":{"id":"TBpaP0zPjvoe"},"source":["Vamos a necesitar separar nuestros datos en un conjunto para entrenar al modelo y otro para probarlo, esto nos va a servir para poder verificar la performance de nuestro modelo con datos que no conoce."]},{"cell_type":"code","metadata":{"id":"xhxlXFEYPoGf"},"source":["from sklearn.model_selection import train_test_split  # una vez hacerlo a mano (con sample) así entienden bien de qué se trata\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, \n","                                                    test_size = 0.25, \n","                                                    random_state = 15)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g97wEpHBX2gG"},"source":["# KNN"]},{"cell_type":"code","metadata":{"id":"BhmHZkxRVo-K"},"source":["# Primero importamos la libreria de sklearn\n","\n","from sklearn.neighbors import KNeighborsClassifier"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LIMZJikMht-E"},"source":["# Inicializamos la clase\n","knn = KNeighborsClassifier(n_neighbors=6)\n","\n","# Entrenamos al modelo\n","knn.fit(X_train, y_train)\n","\n","#predecimos los nuevos valores\n","y_pred = knn.predict(X_test)\n","\n","print('Las predicciones del test set son: \\n {} '.format(y_pred))\n","print('Los y_test reales son: \\n {} '.format(y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BkA0YDSrQIew"},"source":["# Verifiquemos el accuracy del modelo\n","# Para ello podemos utilizar el metodo 'score' sobre el modelo\n","# los argumentos del metodo seran los sets de datos que querramos evaluar.\n","\n","train_accuracy = knn._____(_____, _____)\n","test_accuracy = knn.____(_____, _____)\n","\n","print('El accuracy de prueba es de: {}'.format(train_accuracy))\n","print('El accuracy de test es de: {}'.format(test_accuracy))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qegi0LVdbMRD"},"source":["## Predecir un nuevo valor\n","\n","Una vez creado el modelo vamos a predecir que variedades serian los siguientes dos ejemplos."]},{"cell_type":"code","metadata":{"id":"iHNdLYL7aQ4N"},"source":["# Creamos un arreglo que nos gustaría predecir\n","X_new = np.array([[619, 42, 8, \t137145.12, 3, 0, 0, 112542.58]])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZXSsU8s4bLCw"},"source":["# Seccionar el arreglo que queremos hacer la prediccion\n","prediction = knn.predict(_____)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CbinGpJkb31V"},"source":["print('La clase predecida es: {}'.format(prediction))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n8d8922On5il"},"source":["## Overfitting-Underfitting: n_neighbors\n","\n","Vamos a ver un poco graficamente el efecto del hiperparametro n_neighbors y como se relaciona con el concepto de Overfitting."]},{"cell_type":"code","metadata":{"id":"vsMtBwaymiNI"},"source":["scores = {'n_neighbors': [], 'Training accuracy': [], 'Test accuracy': []}\n","\n","for i in range(1, 25):\n","  knn = KNeighborsClassifier(n_neighbors=i)\n","  knn.fit(X_train, y_train)\n","\n","  scores['n_neighbors'].append(i)\n","  scores['Training accuracy'].append(knn.score(X_train, y_train))\n","  scores['Test accuracy'].append(knn.score(X_test, y_test))\n","\n","scores = pd.DataFrame(scores)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"agdg8Z7fpTlX"},"source":["# setear estilo de grafico\n","\n","sns.set_style('whitegrid')\n","\n","# Vamos a graficar las dos rectas encontradas\n","\n","sns.lineplot(x = 'n_neighbors', \n","             y = 'Training accuracy', \n","             data = scores)\n","\n","sns.lineplot(x = 'n_neighbors', \n","             y = 'Test accuracy', \n","             data = scores)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XWuqpLIAB4TC"},"source":["# Regresión Logística"]},{"cell_type":"markdown","metadata":{"id":"uf_yRWQXCZ3E"},"source":["Para trabajar con regresión logística, vamos a utilizar de la libreria de Sklearn del apartado de modelos lineales, la clase LogisticRegression. Para importarla simplemente la llamamos de la siguiente manera:\n","\n","    from sklearn.linear_model import LogisticRegression\n","\n","A continuación veremos como inicializar una instancia de dicha clase, como entrenar nuestro modelo y predecir nuevos valores.\n","\n","Los Hiperparametros que vamos a estudiar de este modelo son:\n","\n","- C: relacionado a la magnitud de regularización aplicada al modelo.\n","- penalty: que tipo de regularización sera utilizada, por defecto l2.\n","\n","A tener en cuenta:\n","\n","Al ser un modelo lineal, el resultado van a ser coeficientes que multiplican a los atributos y una ordenada al origen, pero como determinamos que clase es la correspondiente?\n","\n","Por el signo, si es postivo predice una clase, si es negativo la otra clase.\n","\n","IMPORTANTE!\n","\n","El modo en el cual operamos con casi todos los modelos de sklearn es practicamente el mismo, con lo cual seguiremos los mismos pasos que en el modelo de KNN."]},{"cell_type":"code","metadata":{"id":"cddXhZNLqgvI"},"source":["from sklearn.linear_model import LogisticRegression"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bbKE1NYNSs8l"},"source":["# separamos el dataset en test y prueba\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, \n","                                                    test_size = 0.3, \n","                                                    random_state = 15)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qvd1xxCQ8fLa"},"source":["# Inicializar la clase de Regresion logistica en la variable lr\n","\n","\n","# Entrenar el modelo con los set de entrenamiento\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_NZC1sN0aY4J"},"source":["print('Los resultados son: \\n')\n","print('El accuracy de prueba es de: {}'.format(lr.score(X_train, y_train)))\n","print('El accuracy de test es de: {}'.format(lr.score(X_test, y_test)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mw7VFKE0986L"},"source":["## Interpretación de datos\n","\n","Ahora interpretemos los datos que nos ofrecen los métodos de predict y predict_proba\n","\n","El primero, es simplemente que clase se predice teniendo en cuenta que el corte de clasificación se encuentra en p = 0.5.\n","\n","El segundo, nos brinda un arreglo con las probabilidades de cada una de las clases.\n","\n","Investiguemos con algun ejemplo estos valores!"]},{"cell_type":"code","metadata":{"id":"izPcqzBd7wtJ"},"source":["lr.predict(X_test[:2])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"89JdPkQr81j2"},"source":["lr.predict_proba(X_test[:2])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qKgP-R9tfGCj"},"source":["**Cambio de umbral de predicción:**\n","\n","Ahora bien, que pasa si queremos cambiar el umbral con el cual determinamos la clase correcta?\n","\n","Facil! Accedemos al valor de la clase que queremos someter a otro umbral de todos los arreglos y lo sometemos a una comprobación logica. El resultado sera un arreglo con booleanos (que se transforman en 1 y 0)\n","\n","**IMPORTANTE:** si queremos comparar correctamente las clases, deberíamos aplicarle la condición logica a la clase que finalmente llamamos 1\n","sino, nos estaría dando la clase opuesta!"]},{"cell_type":"code","metadata":{"id":"t3hW1j3Ydvqj"},"source":["lr.predict_proba(X_test[:2])[:, 1] > 0.25"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tET5rqNSDuvJ"},"source":["# por ultimo volvemos a introducir el concepto de Confusion maxtrix visto en la teoria\n","\n","from sklearn.metrics import classification_report, confusion_matrix\n","\n","confusion_matrix(y_test, lr.predict(X_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3bPI3vr3GxZ8"},"source":["# ahora vamos a ver el reporte de clasificación\n","\n","print(classification_report(y_test, lr.predict(X_test)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wkrtg9El-fOf"},"source":["# Cross validation"]},{"cell_type":"markdown","metadata":{"id":"Dr9PTMwQf_ED"},"source":["**Pasos para la composición del código**\n","\n","- Importar las librerias (LogisticRegression ya la tenemos importada asi que solo cross_val_score)\n","\n","      from sklearn.model_selection import cross_val_score\n","\n","- Inicializar el modelo (como siempre)\n","      lr = LogisticRegression()\n","- Inicializar cross validation\n","      cv_score = cross_val_score(modelo a utilizar, X, y, cv = cantidad de splits)"]},{"cell_type":"code","metadata":{"id":"ZoPib5DD-gup"},"source":["from sklearn.model_selection import cross_val_score\n","\n","lr = LogisticRegression()\n","\n","cv_score = cross_val_score(lr, X, y, cv=5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qHSbZ-wfAfic"},"source":["cv_score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cSPwWlW9An81"},"source":["print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cv_score.mean(), cv_score.std() * 2))"],"execution_count":null,"outputs":[]}]}